{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:20.901530400Z",
     "start_time": "2023-12-01T13:21:20.840017200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv, to_hetero, GCNConv\n",
    "from torch_geometric.transforms import RandomLinkSplit, ToUndirected\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "data_folder = \"../data/interm/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "users = pd.read_csv(data_folder + \"users.csv\")\n",
    "items = pd.read_csv(data_folder + \"items.csv\")\n",
    "ratings = pd.read_csv(data_folder + \"ratings.csv\")\n",
    "genres = pd.read_csv(\"../data/raw/ml-100k/u.genre\", delimiter=\"|\", names=[\"name\",\"index\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:20.930530200Z",
     "start_time": "2023-12-01T13:21:20.850017600Z"
    }
   },
   "id": "cc96f440cf052ce5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Edges: ratings\n",
    "Nodes: users, items\n",
    "Graph type: bipartite"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51b93cb251d5ab72"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def create_torch_edges(ratings):\n",
    "    src = ratings[\"user_id\"] - 1\n",
    "    dst = ratings[\"item_id\"] - 1\n",
    "    attrs = ratings[\"rating\"]\n",
    "    \n",
    "    edge_index = torch.tensor([src, dst], dtype=torch.int64)\n",
    "    edge_attr = torch.tensor(attrs)\n",
    "    \n",
    "    return edge_index, edge_attr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:20.930530200Z",
     "start_time": "2023-12-01T13:21:20.882055Z"
    }
   },
   "id": "41273aa8452e27d4"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "edge_index, edge_attr = create_torch_edges(ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:21.056048200Z",
     "start_time": "2023-12-01T13:21:20.897533200Z"
    }
   },
   "id": "28f9ad75f57cfea7"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 100000])"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:21.071049900Z",
     "start_time": "2023-12-01T13:21:21.056048200Z"
    }
   },
   "id": "7fed97aa2a26e3c4"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "      movie_id                                movie_title  unknown  Action  \\\n0            1                           Toy Story (1995)        0       0   \n1            2                           GoldenEye (1995)        0       1   \n2            3                          Four Rooms (1995)        0       0   \n3            4                          Get Shorty (1995)        0       1   \n4            5                             Copycat (1995)        0       0   \n...        ...                                        ...      ...     ...   \n1677      1678                          Mat' i syn (1997)        0       0   \n1678      1679                           B. Monkey (1998)        0       0   \n1679      1680                       Sliding Doors (1998)        0       0   \n1680      1681                        You So Crazy (1994)        0       0   \n1681      1682  Scream of Stone (Schrei aus Stein) (1991)        0       0   \n\n      Adventure  Animation  Children's  Comedy  Crime  Documentary  ...  \\\n0             0          1           1       1      0            0  ...   \n1             1          0           0       0      0            0  ...   \n2             0          0           0       0      0            0  ...   \n3             0          0           0       1      0            0  ...   \n4             0          0           0       0      1            0  ...   \n...         ...        ...         ...     ...    ...          ...  ...   \n1677          0          0           0       0      0            0  ...   \n1678          0          0           0       0      0            0  ...   \n1679          0          0           0       0      0            0  ...   \n1680          0          0           0       1      0            0  ...   \n1681          0          0           0       0      0            0  ...   \n\n      Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  \\\n0             0       0        0        0        0       0         0    0   \n1             0       0        0        0        0       0         1    0   \n2             0       0        0        0        0       0         1    0   \n3             0       0        0        0        0       0         0    0   \n4             0       0        0        0        0       0         1    0   \n...         ...     ...      ...      ...      ...     ...       ...  ...   \n1677          0       0        0        0        0       0         0    0   \n1678          0       0        0        0        1       0         1    0   \n1679          0       0        0        0        1       0         0    0   \n1680          0       0        0        0        0       0         0    0   \n1681          0       0        0        0        0       0         0    0   \n\n      Western  release_year  \n0           0        1995.0  \n1           0        1995.0  \n2           0        1995.0  \n3           0        1995.0  \n4           0        1995.0  \n...       ...           ...  \n1677        0        1998.0  \n1678        0        1998.0  \n1679        0        1998.0  \n1680        0        1994.0  \n1681        0        1996.0  \n\n[1682 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>movie_title</th>\n      <th>unknown</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children's</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>Documentary</th>\n      <th>...</th>\n      <th>Film-Noir</th>\n      <th>Horror</th>\n      <th>Musical</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n      <th>War</th>\n      <th>Western</th>\n      <th>release_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Four Rooms (1995)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Get Shorty (1995)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Copycat (1995)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1677</th>\n      <td>1678</td>\n      <td>Mat' i syn (1997)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1998.0</td>\n    </tr>\n    <tr>\n      <th>1678</th>\n      <td>1679</td>\n      <td>B. Monkey (1998)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1998.0</td>\n    </tr>\n    <tr>\n      <th>1679</th>\n      <td>1680</td>\n      <td>Sliding Doors (1998)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1998.0</td>\n    </tr>\n    <tr>\n      <th>1680</th>\n      <td>1681</td>\n      <td>You So Crazy (1994)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1994.0</td>\n    </tr>\n    <tr>\n      <th>1681</th>\n      <td>1682</td>\n      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1996.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1682 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:21.114215Z",
     "start_time": "2023-12-01T13:21:21.072051Z"
    }
   },
   "id": "341b1c3bc755dea9"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7df45f30f02422ca89db849a87a2712"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def SequenceEncoder(movie_titles , model_name=None):\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    title_embeddings = model.encode(movie_titles, show_progress_bar=True,\n",
    "                              convert_to_tensor=True, device=device)\n",
    "    \n",
    "    return title_embeddings.to(\"cpu\")\n",
    "\n",
    "item_title = SequenceEncoder(items[\"movie_title\"], model_name='all-MiniLM-L6-v2')\n",
    "item_genres = torch.tensor(items[genres.name].to_numpy(), dtype=torch.bool)\n",
    "item_release_year = torch.tensor(items[\"release_year\"].to_numpy()[:,np.newaxis], dtype=torch.int32)\n",
    "\n",
    "item_x = torch.cat((item_title, item_genres), dim=-1).float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:21.910552Z",
     "start_time": "2023-12-01T13:21:21.086053Z"
    }
   },
   "id": "a201cb82c6e6699e"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "     user_id  age zip_code   male  female  occupation_technician  \\\n0          1   24    85711   True   False                   True   \n1          2   53    94043  False    True                  False   \n2          3   23    32067   True   False                  False   \n3          4   24    43537   True   False                   True   \n4          5   33    15213  False    True                  False   \n..       ...  ...      ...    ...     ...                    ...   \n938      939   26    33319  False    True                  False   \n939      940   32    02215   True   False                  False   \n940      941   20    97229   True   False                  False   \n941      942   48    78209  False    True                  False   \n942      943   22    77841   True   False                  False   \n\n     occupation_other  occupation_writer  occupation_executive  \\\n0               False              False                 False   \n1                True              False                 False   \n2               False               True                 False   \n3               False              False                 False   \n4                True              False                 False   \n..                ...                ...                   ...   \n938             False              False                 False   \n939             False              False                 False   \n940             False              False                 False   \n941             False              False                 False   \n942             False              False                 False   \n\n     occupation_administrator  ...  occupation_librarian  \\\n0                       False  ...                 False   \n1                       False  ...                 False   \n2                       False  ...                 False   \n3                       False  ...                 False   \n4                       False  ...                 False   \n..                        ...  ...                   ...   \n938                     False  ...                 False   \n939                      True  ...                 False   \n940                     False  ...                 False   \n941                     False  ...                  True   \n942                     False  ...                 False   \n\n     occupation_homemaker  occupation_artist  occupation_engineer  \\\n0                   False              False                False   \n1                   False              False                False   \n2                   False              False                False   \n3                   False              False                False   \n4                   False              False                False   \n..                    ...                ...                  ...   \n938                 False              False                False   \n939                 False              False                False   \n940                 False              False                False   \n941                 False              False                False   \n942                 False              False                False   \n\n     occupation_marketing  occupation_none  occupation_healthcare  \\\n0                   False            False                  False   \n1                   False            False                  False   \n2                   False            False                  False   \n3                   False            False                  False   \n4                   False            False                  False   \n..                    ...              ...                    ...   \n938                 False            False                  False   \n939                 False            False                  False   \n940                 False            False                  False   \n941                 False            False                  False   \n942                 False            False                  False   \n\n     occupation_retired  occupation_salesman  occupation_doctor  \n0                 False                False              False  \n1                 False                False              False  \n2                 False                False              False  \n3                 False                False              False  \n4                 False                False              False  \n..                  ...                  ...                ...  \n938               False                False              False  \n939               False                False              False  \n940               False                False              False  \n941               False                False              False  \n942               False                False              False  \n\n[943 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>zip_code</th>\n      <th>male</th>\n      <th>female</th>\n      <th>occupation_technician</th>\n      <th>occupation_other</th>\n      <th>occupation_writer</th>\n      <th>occupation_executive</th>\n      <th>occupation_administrator</th>\n      <th>...</th>\n      <th>occupation_librarian</th>\n      <th>occupation_homemaker</th>\n      <th>occupation_artist</th>\n      <th>occupation_engineer</th>\n      <th>occupation_marketing</th>\n      <th>occupation_none</th>\n      <th>occupation_healthcare</th>\n      <th>occupation_retired</th>\n      <th>occupation_salesman</th>\n      <th>occupation_doctor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>85711</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>53</td>\n      <td>94043</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23</td>\n      <td>32067</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24</td>\n      <td>43537</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>33</td>\n      <td>15213</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>938</th>\n      <td>939</td>\n      <td>26</td>\n      <td>33319</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>940</td>\n      <td>32</td>\n      <td>02215</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>941</td>\n      <td>20</td>\n      <td>97229</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>942</td>\n      <td>48</td>\n      <td>78209</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>943</td>\n      <td>22</td>\n      <td>77841</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:21.924551600Z",
     "start_time": "2023-12-01T13:21:21.907550400Z"
    }
   },
   "id": "d1942a41fd8d13cb"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['85711', '94043', '32067', '43537', '15213', '98101', '91344',\n       '05201', '01002', '90703', '30329', '06405', '29206', '55106',\n       '97301', '10309', '06355', '37212', '02138', '95660', '30068',\n       '40206', '48197', '94533', '55107', '21044', '30030', '55369',\n       '94043', '55436', '10003', '78741', '27510', '42141', '42459',\n       '93117', '55105', '54467', '01040', '27514', '80525', '17870',\n       '20854', '46260', '50233', '46538', '07102', '12550', '76111',\n       '52245', '16509', '55105', '55414', '66315', '01331', '46260',\n       '84010', '52246', '08403', '06472', '30040', '97214', '75240',\n       '43202', '48118', '80521', '60402', '22904', '55337', '60067',\n       '98034', '73034', '41850', 'T8H1N', '08816', '02215', '29379',\n       '61801', '03755', '52241', '21218', '22902', '44133', '55369',\n       '20003', '46005', '89503', '11701', '68106', '78155', '01913',\n       '80525', '23112', '71457', '10707', '75206', '98006', '90291',\n       '63129', '90254', '05146', '30220', '55108', '55108', '94043',\n       '55125', '60466', '63130', '55423', '77840', '90630', '60613',\n       '95032', '75013', '17110', '97232', '16125', '90210', '67401',\n       '06260', '99603', '22206', '20008', '60615', '22202', '20015',\n       '73439', '20009', '07039', '60115', '15237', '94612', '78602',\n       '80236', '38401', '97365', '84408', '53211', '08904', '32250',\n       '36117', '48118', '08832', '20910', 'V3N4P', '83814', '02143',\n       '97006', '17325', '02139', '48103', '68767', '60641', '53703',\n       '11217', '08360', '70808', '27606', '55346', '66215', '55104',\n       '15610', '97212', '80123', '53715', '55113', 'L9G2B', '80127',\n       '53705', '30067', '78750', '22207', '22306', '52302', '21911',\n       '07030', '19104', '49512', '20755', '60202', '21218', '33884',\n       '27708', '76013', '97403', '00000', '16801', '29440', '95014',\n       '95938', '95161', '90840', '49931', '02154', '93555', '55105',\n       '75094', '55414', '17604', '93402', 'E2A4H', '60201', '32301',\n       '10960', '06371', '53115', '92037', '01720', '85710', '03060',\n       '32605', '61401', '55345', '11231', '63033', '02215', '11727',\n       '06513', '43212', '78205', '20685', '27502', '47906', '43512',\n       '58202', '92103', '60659', '22003', '22903', '14476', '01080',\n       '99709', '98682', '94702', '22973', '53214', '63146', '44124',\n       '95628', '20784', '20001', '31404', '60201', '80525', '55109',\n       '28734', '20770', '37235', '84103', '95110', '85032', '07733',\n       '22903', '42647', '07029', '39042', '77005', '77801', '48823',\n       '89801', '85202', '78264', '55346', '90064', '84601', '78756',\n       '83716', '19422', '43201', '63119', '22932', '53706', '10016',\n       '55414', '92064', '95064', '55406', '30033', '85251', '22903',\n       '06059', '20057', '55305', '92629', '53713', '15217', '31211',\n       '23226', '94619', '93550', '44106', '94703', '60804', '92110',\n       '50325', '16803', '98103', '01581', '63108', '55106', '55439',\n       '77904', '14853', '71701', '94086', '73132', '55454', '95076',\n       '70802', '91711', '73071', '02110', '60035', '08043', '18301',\n       '77009', '13210', '06518', '22030', '24060', '55413', '50613',\n       '19149', '02176', '02139', '15235', '11101', '06779', '01720',\n       '33884', '91344', '40504', 'V0R2M', '30002', '33775', '42101',\n       '10522', '59717', '37901', '80123', '44405', '98006', '30093',\n       '94117', '94143', '76059', '90210', '45660', '61455', '97301',\n       '49938', '55105', '28480', '48197', '60135', '92688', '98133',\n       '10022', '61801', '98027', '44074', '85233', '87501', '01810',\n       '20009', '50670', '37411', '92113', '91335', '08534', '99206',\n       '66046', '55116', '78746', '37777', '10010', '18015', '02859',\n       '98117', '55117', '94608', '01824', '75204', '45218', '10003',\n       '43221', '37412', '36106', '83702', '85016', '84604', '59801',\n       '83686', '96819', '44092', '94551', '27514', '60008', '92374',\n       '78213', '84107', '95129', '06811', '55108', '10019', '93109',\n       '03261', '61755', '98225', '94025', '44691', '15222', '78212',\n       '38115', '85711', '92626', '48103', '21206', '43215', '02140',\n       '55105', '94533', '91606', '55422', '58644', '01602', '85258',\n       '55414', '29205', '98199', '92629', '50311', '11211', '49705',\n       '60007', '17345', '20009', '43204', '20817', '48076', '55013',\n       '85282', '33308', '53202', '92653', '60201', '55113', '10021',\n       '55021', '11758', '48446', '28018', '06333', '97330', '83709',\n       '31820', '30011', 'Y1A6B', '29201', '60630', '98102', '02918',\n       '75218', '94583', '05001', '90804', '91201', '02341', '78628',\n       '10021', '77459', '87544', '94708', '93711', '75230', '60440',\n       '02125', '10019', '55409', '98257', '37771', '40256', '43212',\n       '21208', '95821', '93101', '92121', '21012', '45218', 'V5A2B',\n       '53711', '94618', '60090', '49428', '03052', '55414', '50112',\n       '55408', '75006', '94305', '10025', '23092', '27514', '92115',\n       '20657', '03869', '28450', '19382', '10011', '98038', '21250',\n       '20090', '26241', '20707', '49508', '10021', '55454', '99709',\n       '55320', '12603', '02146', '55443', '04102', '02159', '19711',\n       '97124', '12180', '55104', '44224', '94040', '97408', '92705',\n       '02324', '05464', '80302', '30078', '22902', '21010', '80303',\n       '91201', '84302', '60515', '95123', '29464', '08052', '22911',\n       '14534', '95468', '45680', '95453', '55414', '68147', '62901',\n       '62901', '23227', '30606', '11217', '63132', '10022', '10003',\n       '60005', '20879', '32707', '94591', '55422', '14627', '10003',\n       '01915', '91903', '14627', '01945', '20003', '48911', '53188',\n       '46032', '98281', '77845', 'M7A1A', '48103', '17961', '94131',\n       '93003', '29631', '27511', '98501', '79508', '14216', '93063',\n       '90034', '82435', '92093', '97520', '68767', 'M4J2K', '31909',\n       '77073', '84116', '43085', 'R3T5K', '02320', '99687', '34656',\n       '47905', '11787', '33716', '63044', '02154', '10003', '55106',\n       '21227', '77008', '79070', '29678', '80227', '27705', '50613',\n       '11201', '44212', '44134', '81648', '60402', '14850', '60187',\n       '30067', '20723', '19807', '08034', '94306', '44224', '55408',\n       '38866', '55454', '55414', 'T8H1N', '23237', '48043', '74101',\n       '01940', '12065', '61801', '60626', '95521', '55122', '63645',\n       '53211', '51250', '45810', '91351', '39762', '83814', '02903',\n       '22911', '55105', '78739', '60657', '10314', '78704', '92626',\n       '54248', '77380', '98121', '19102', '19341', '94115', '55412',\n       '61820', '01970', '10016', '20009', '21114', '91919', '90095',\n       '22906', '55337', '28814', '32712', '99835', '61462', '54302',\n       '90405', '97208', '55128', '23509', '55414', '55409', '26506',\n       '27713', '60476', '45439', '63304', '60089', '18053', '85210',\n       '06365', '38115', '94920', '77042', '06906', '96754', '76309',\n       '56321', '89104', '49512', '91105', '54494', '55454', '19146',\n       '96349', 'N4T1A', '92020', '15203', '54901', '07204', '55343',\n       '91206', '44265', '84105', '64118', 'V0R2H', '16506', '11238',\n       '17331', '94403', '40243', '91711', '80538', '78741', '94306',\n       '56567', '32114', '70403', '98405', '60630', '63108', '85719',\n       '94618', '98072', '95403', '73162', '22206', '63108', '29210',\n       '92660', '47024', '55113', '19047', '93612', '94720', '80919',\n       '32303', '90034', '21201', '91206', '62901', '97007', '90247',\n       '55104', '53706', '68503', '14211', '97302', '95050', '02113',\n       '62903', '33066', '10960', '00000', '12866', '06927', '14216',\n       '15232', '27105', '55414', '80027', '90036', '51157', '01810',\n       '01960', 'K7L5J', '94560', '48825', '33205', '77081', '91040',\n       '23322', '01754', '98620', '05779', '55420', '80913', '20064',\n       '12205', '85281', '57197', '08610', '33755', '62522', '64131',\n       '19716', '55337', '92154', '34105', '78212', '61820', '20009',\n       '11217', '93555', '90016', '30803', '80526', '73013', '76234',\n       '02136', '12345', '28806', '20755', '60152', '27514', '40205',\n       '37725', '77845', '53144', '50322', '15017', '05452', '77048',\n       '80228', '85282', '80209', '53066', '33765', '77042', '90019',\n       '64153', '11577', '10018', '55409', '01375', '90814', '55406',\n       '47401', '93055', '44212', '95662', '97405', '47130', '55417',\n       '02146', '25652', '78390', '29646', '94086', '40515', '55408',\n       '04988', '97215', 'V1G4L', '09645', '06492', '48322', '14085',\n       '13820', '60089', '63021', '11231', '60302', '92507', '55303',\n       '10025', '65203', '44648', '74078', '33763', '37076', '35802',\n       '20902', '77504', '98027', '55337', '83702', '43017', '40503',\n       '50266', '55337', '95316', '61820', '27249', '17036', '78704',\n       '97301', '03062', '45243', '95823', '74075', '32301', '91505',\n       '33484', '61755', '55116', '18505', 'L1V3W', '97203', '20850',\n       '61073', '30350', '70124', '80526', '68504', '53171', '29301',\n       '53210', '06512', '76201', '08105', '60614', 'N2L5N', '20006',\n       '70116', '14216', '90008', '98801', '21114', 'E2E3R', '11753',\n       '49036', '01701', '55428', '55408', '53711', '07310', '33556',\n       '06437', '48105', '22902', '66221', '32789', '98072', '55038',\n       '33319', '02215', '97229', '78209', '77841'], dtype=object)"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.zip_code.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:21.949548900Z",
     "start_time": "2023-12-01T13:21:21.923549300Z"
    }
   },
   "id": "d496e7bffcfd2278"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "user_ages = torch.tensor(users[\"age\"].to_numpy()[:,np.newaxis], dtype=torch.uint8)\n",
    "user_sex = torch.tensor(users[[\"male\", \"female\"]].to_numpy(), dtype=torch.bool)\n",
    "occupations = [i for i in users.keys() if i.startswith(\"occupation_\")]\n",
    "user_occupation = torch.tensor(users[occupations].to_numpy(), dtype=torch.bool)\n",
    "user_x = torch.cat((user_ages, user_sex, user_occupation), dim=-1).float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:22.014064800Z",
     "start_time": "2023-12-01T13:21:21.940550900Z"
    }
   },
   "id": "38af715c6383f78e"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "data['user'].x = user_x\n",
    "data['item'].x = item_x\n",
    "data['user', 'rates', 'item'].edge_index = edge_index\n",
    "data['user', 'rates', 'item'].edge_label = edge_attr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:22.032065900Z",
     "start_time": "2023-12-01T13:21:21.955550500Z"
    }
   },
   "id": "48d66c8cb0521265"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "data = ToUndirected()(data)\n",
    "del data['item', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n",
    "data = data.to(device)\n",
    "\n",
    "# Perform a link-level split into training, validation, and test edges.\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'item')],\n",
    "    rev_edge_types=[('item', 'rev_rates', 'user')],\n",
    ")(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:22.051066500Z",
     "start_time": "2023-12-01T13:21:21.969549700Z"
    }
   },
   "id": "1b42a5cb4e8e1e35"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "weight = torch.bincount(train_data['user', 'rates', 'item'].edge_label)\n",
    "weight = weight.max() / weight\n",
    "def weighted_mse_loss(pred, target, weight=None):\n",
    "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
    "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:22.052066600Z",
     "start_time": "2023-12-01T13:21:21.985554900Z"
    }
   },
   "id": "c288c9c483405a7e"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "from torch.nn import Dropout\n",
    "from torch_geometric.nn import GATv2Conv, RGCNConv, HeteroConv, GINConv\n",
    "from torch_geometric.utils.dropout import *\n",
    "\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # these convolutions have been replicated to match the number of edge types\\\n",
    "        self.conv1 = GATv2Conv((-1, -1), hidden_channels, add_self_loops=False)\n",
    "        self.conv2 = GATv2Conv((-1, -1), hidden_channels, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, n_factors, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * n_factors, hidden_channels)\n",
    "        self.dropout = Dropout()\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin4 = Linear(hidden_channels, 1)\n",
    "        \n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        # concat user and movie embeddings\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['item'][col]], dim=-1)\n",
    "        # concatenated embeddings passed to linear layer\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.dropout(z)\n",
    "        z = self.lin2(z).relu()\n",
    "        z = self.dropout(z)\n",
    "        z = self.lin3(z).relu()\n",
    "        z = self.dropout(z)\n",
    "        z = self.lin4(z)\n",
    "        return z.view(-1)\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, n_factors, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(n_factors)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(n_factors, hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        # z_dict contains dictionary of movie and user embeddings returned from GraphSage\n",
    "        edge_label_index, mask = dropout_edge(edge_label_index, p=0.25, training=self.training)\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index), mask\n",
    "model = Model(n_factors=150, hidden_channels=500).to(device)\n",
    "# Due to lazy initialization, we need to run one model step so the number\n",
    "# of parameters can be inferred:\n",
    "with torch.no_grad():\n",
    "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:22.053065200Z",
     "start_time": "2023-12-01T13:21:22.006065600Z"
    }
   },
   "id": "1ad44484c84b9b28"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "\n",
    "loss_f = MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred, mask = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['user', 'rates', 'item'].edge_label_index)\n",
    "    target = train_data['user', 'rates', 'item'].edge_label\n",
    "    loss = weighted_mse_loss(pred, target[mask], weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:22.054066900Z",
     "start_time": "2023-12-01T13:21:22.034066400Z"
    }
   },
   "id": "6d258c1985d72b5b"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    pred, _ = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['user', 'rates', 'item'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = data['user', 'rates', 'item'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:21:22.067066600Z",
     "start_time": "2023-12-01T13:21:22.049065900Z"
    }
   },
   "id": "d55867059c4f30f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 19.1996, Train: 3.0232, Val: 3.0255, Test: 3.0288\n",
      "Epoch: 002, Loss: 11.4756, Train: 1.9265, Val: 1.9305, Test: 1.9363\n",
      "Epoch: 003, Loss: 4.7593, Train: 1.4633, Val: 1.4573, Test: 1.4460\n",
      "Epoch: 004, Loss: 11.8741, Train: 1.1884, Val: 1.1886, Test: 1.1911\n",
      "Epoch: 005, Loss: 5.1398, Train: 1.7156, Val: 1.7183, Test: 1.7225\n",
      "Epoch: 006, Loss: 4.0277, Train: 2.1691, Val: 2.1709, Test: 2.1750\n",
      "Epoch: 007, Loss: 5.3483, Train: 2.3788, Val: 2.3803, Test: 2.3837\n",
      "Epoch: 008, Loss: 6.3330, Train: 2.4130, Val: 2.4144, Test: 2.4173\n",
      "Epoch: 009, Loss: 6.5116, Train: 2.3166, Val: 2.3178, Test: 2.3204\n",
      "Epoch: 010, Loss: 6.0788, Train: 2.1055, Val: 2.1065, Test: 2.1088\n",
      "Epoch: 011, Loss: 5.1364, Train: 1.7929, Val: 1.7936, Test: 1.7953\n",
      "Epoch: 012, Loss: 4.1781, Train: 1.4297, Val: 1.4294, Test: 1.4304\n",
      "Epoch: 013, Loss: 3.7496, Train: 1.1775, Val: 1.1759, Test: 1.1756\n",
      "Epoch: 014, Loss: 4.3516, Train: 1.1249, Val: 1.1225, Test: 1.1215\n",
      "Epoch: 015, Loss: 5.1964, Train: 1.1384, Val: 1.1363, Test: 1.1355\n",
      "Epoch: 016, Loss: 4.7842, Train: 1.2470, Val: 1.2459, Test: 1.2458\n",
      "Epoch: 017, Loss: 4.0276, Train: 1.4618, Val: 1.4616, Test: 1.4620\n",
      "Epoch: 018, Loss: 3.7816, Train: 1.6821, Val: 1.6824, Test: 1.6831\n",
      "Epoch: 019, Loss: 3.9589, Train: 1.8283, Val: 1.8288, Test: 1.8296\n",
      "Epoch: 020, Loss: 4.2487, Train: 1.8823, Val: 1.8829, Test: 1.8837\n",
      "Epoch: 021, Loss: 4.3907, Train: 1.8495, Val: 1.8500, Test: 1.8507\n",
      "Epoch: 022, Loss: 4.3228, Train: 1.7434, Val: 1.7437, Test: 1.7443\n",
      "Epoch: 023, Loss: 4.0723, Train: 1.5869, Val: 1.5869, Test: 1.5872\n",
      "Epoch: 024, Loss: 3.8521, Train: 1.4173, Val: 1.4169, Test: 1.4168\n",
      "Epoch: 025, Loss: 3.7603, Train: 1.2867, Val: 1.2857, Test: 1.2853\n",
      "Epoch: 026, Loss: 3.9102, Train: 1.2303, Val: 1.2290, Test: 1.2284\n",
      "Epoch: 027, Loss: 4.0670, Train: 1.2417, Val: 1.2405, Test: 1.2399\n",
      "Epoch: 028, Loss: 4.0658, Train: 1.3125, Val: 1.3116, Test: 1.3112\n",
      "Epoch: 029, Loss: 3.8557, Train: 1.4242, Val: 1.4238, Test: 1.4236\n",
      "Epoch: 030, Loss: 3.7536, Train: 1.5394, Val: 1.5393, Test: 1.5393\n",
      "Epoch: 031, Loss: 3.7681, Train: 1.6229, Val: 1.6230, Test: 1.6231\n",
      "Epoch: 032, Loss: 3.8806, Train: 1.6599, Val: 1.6600, Test: 1.6602\n",
      "Epoch: 033, Loss: 3.9466, Train: 1.6451, Val: 1.6453, Test: 1.6454\n",
      "Epoch: 034, Loss: 3.9142, Train: 1.5850, Val: 1.5850, Test: 1.5850\n",
      "Epoch: 035, Loss: 3.8133, Train: 1.4958, Val: 1.4956, Test: 1.4955\n",
      "Epoch: 036, Loss: 3.7094, Train: 1.4023, Val: 1.4018, Test: 1.4015\n",
      "Epoch: 037, Loss: 3.7356, Train: 1.3363, Val: 1.3355, Test: 1.3351\n",
      "Epoch: 038, Loss: 3.8188, Train: 1.3158, Val: 1.3149, Test: 1.3144\n",
      "Epoch: 039, Loss: 3.8205, Train: 1.3384, Val: 1.3377, Test: 1.3372\n",
      "Epoch: 040, Loss: 3.7640, Train: 1.3946, Val: 1.3941, Test: 1.3937\n",
      "Epoch: 041, Loss: 3.7193, Train: 1.4644, Val: 1.4641, Test: 1.4638\n",
      "Epoch: 042, Loss: 3.7174, Train: 1.5265, Val: 1.5264, Test: 1.5262\n",
      "Epoch: 043, Loss: 3.7215, Train: 1.5629, Val: 1.5628, Test: 1.5627\n",
      "Epoch: 044, Loss: 3.7411, Train: 1.5658, Val: 1.5658, Test: 1.5656\n",
      "Epoch: 045, Loss: 3.7707, Train: 1.5399, Val: 1.5398, Test: 1.5396\n",
      "Epoch: 046, Loss: 3.7128, Train: 1.4928, Val: 1.4925, Test: 1.4923\n",
      "Epoch: 047, Loss: 3.7005, Train: 1.4413, Val: 1.4409, Test: 1.4405\n",
      "Epoch: 048, Loss: 3.6912, Train: 1.4043, Val: 1.4038, Test: 1.4033\n",
      "Epoch: 049, Loss: 3.7322, Train: 1.3950, Val: 1.3944, Test: 1.3940\n",
      "Epoch: 050, Loss: 3.7347, Train: 1.4191, Val: 1.4186, Test: 1.4182\n",
      "Epoch: 051, Loss: 3.7142, Train: 1.4645, Val: 1.4642, Test: 1.4638\n",
      "Epoch: 052, Loss: 3.7026, Train: 1.5141, Val: 1.5139, Test: 1.5136\n",
      "Epoch: 053, Loss: 3.6899, Train: 1.5475, Val: 1.5474, Test: 1.5472\n",
      "Epoch: 054, Loss: 3.6812, Train: 1.5541, Val: 1.5541, Test: 1.5538\n",
      "Epoch: 055, Loss: 3.6913, Train: 1.5372, Val: 1.5371, Test: 1.5368\n",
      "Epoch: 056, Loss: 3.6543, Train: 1.5040, Val: 1.5038, Test: 1.5035\n",
      "Epoch: 057, Loss: 3.6814, Train: 1.4666, Val: 1.4662, Test: 1.4659\n",
      "Epoch: 058, Loss: 3.6825, Train: 1.4562, Val: 1.4558, Test: 1.4555\n",
      "Epoch: 059, Loss: 3.6336, Train: 1.4736, Val: 1.4732, Test: 1.4729\n",
      "Epoch: 060, Loss: 3.6751, Train: 1.5149, Val: 1.5147, Test: 1.5144\n",
      "Epoch: 061, Loss: 3.6470, Train: 1.5569, Val: 1.5568, Test: 1.5566\n",
      "Epoch: 062, Loss: 3.6427, Train: 1.5793, Val: 1.5792, Test: 1.5791\n",
      "Epoch: 063, Loss: 3.6899, Train: 1.5798, Val: 1.5797, Test: 1.5795\n",
      "Epoch: 064, Loss: 3.6674, Train: 1.5557, Val: 1.5556, Test: 1.5554\n",
      "Epoch: 065, Loss: 3.6274, Train: 1.5229, Val: 1.5227, Test: 1.5224\n",
      "Epoch: 066, Loss: 3.6031, Train: 1.5214, Val: 1.5211, Test: 1.5209\n",
      "Epoch: 067, Loss: 3.6199, Train: 1.5578, Val: 1.5577, Test: 1.5575\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1000):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-01T13:21:22.066066600Z"
    }
   },
   "id": "b3bb283aa6640b24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total_users = len(users)\n",
    "total_movies = len(items)\n",
    "movie_recs = []\n",
    "for user_id in tqdm(range(0, total_users)):\n",
    "    user_row = torch.tensor([user_id] * total_movies)\n",
    "    all_movie_ids = torch.arange(total_movies)\n",
    "    edge_label_index = torch.stack([user_row, all_movie_ids], dim=0)\n",
    "    pred, _ = model(data.x_dict, data.edge_index_dict,\n",
    "             edge_label_index)\n",
    "    # we will only select movies for the user where the predicting rating is =5\n",
    "    rec_movie_ids = (pred > 4.9).nonzero(as_tuple=True)\n",
    "    top_ten_recs = [rec_movies + 1 for rec_movies in rec_movie_ids[0].tolist()] \n",
    "    movie_recs.append({'user': user_id + 1, 'rec_movies': top_ten_recs})"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "62c84c7bc07998ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_recs"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6b15a707d27ccd21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user = 481"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3e4928b6f6dea04a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_ids = ratings[ratings.user_id == user].iterrows()\n",
    "for i in movie_ids:\n",
    "    _, row = i\n",
    "    item = items[items[\"movie_id\"] == row.item_id]\n",
    "    mean_rating = ratings[ratings[\"item_id\"] == row.item_id][\"rating\"].mean()\n",
    "    print(item[\"movie_title\"].tolist()[0], row.rating, str(mean_rating)[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a4e7d12df9000267"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in movie_recs[user - 1][\"rec_movies\"]:\n",
    "    movie = items[items[\"movie_id\"] == i]\n",
    "    movie_id = movie[\"movie_id\"].tolist()[0]\n",
    "    mean_rating = ratings[ratings[\"item_id\"] == movie_id][\"rating\"].mean()\n",
    "    rated = ratings[ratings[\"item_id\"] == movie_id][\"user_id\"].notnull().sum()\n",
    "    print(movie[\"movie_title\"].tolist()[0], str(mean_rating)[:3], rated)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "77f8c036011263f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
