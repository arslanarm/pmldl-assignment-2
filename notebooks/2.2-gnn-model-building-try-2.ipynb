{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:40.060732900Z",
     "start_time": "2023-12-01T14:16:39.995214700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv, to_hetero, GCNConv\n",
    "from torch_geometric.transforms import RandomLinkSplit, ToUndirected\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "data_folder = \"../data/interm/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "outputs": [],
   "source": [
    "users = pd.read_csv(data_folder + \"users.csv\")\n",
    "items = pd.read_csv(data_folder + \"items.csv\")\n",
    "ratings = pd.read_csv(data_folder + \"ratings.csv\")\n",
    "genres = pd.read_csv(\"../data/raw/ml-100k/u.genre\", delimiter=\"|\", names=[\"name\",\"index\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:40.102733500Z",
     "start_time": "2023-12-01T14:16:40.004214500Z"
    }
   },
   "id": "cc96f440cf052ce5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Edges: ratings\n",
    "Nodes: users, items\n",
    "Graph type: bipartite"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51b93cb251d5ab72"
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "outputs": [],
   "source": [
    "def create_torch_edges(ratings):\n",
    "    src = ratings[\"user_id\"] - 1\n",
    "    dst = ratings[\"item_id\"] - 1\n",
    "    attrs = ratings[\"rating\"]\n",
    "    \n",
    "    edge_index = torch.tensor([src, dst], dtype=torch.int64)\n",
    "    edge_attr = torch.tensor(attrs)\n",
    "    \n",
    "    return edge_index, edge_attr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:40.102733500Z",
     "start_time": "2023-12-01T14:16:40.034222500Z"
    }
   },
   "id": "41273aa8452e27d4"
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "outputs": [],
   "source": [
    "edge_index, edge_attr = create_torch_edges(ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:40.203251700Z",
     "start_time": "2023-12-01T14:16:40.049734200Z"
    }
   },
   "id": "28f9ad75f57cfea7"
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 100000])"
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:40.219252400Z",
     "start_time": "2023-12-01T14:16:40.205251900Z"
    }
   },
   "id": "7fed97aa2a26e3c4"
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "outputs": [
    {
     "data": {
      "text/plain": "      movie_id                                movie_title  unknown  Action  \\\n0            1                           Toy Story (1995)        0       0   \n1            2                           GoldenEye (1995)        0       1   \n2            3                          Four Rooms (1995)        0       0   \n3            4                          Get Shorty (1995)        0       1   \n4            5                             Copycat (1995)        0       0   \n...        ...                                        ...      ...     ...   \n1677      1678                          Mat' i syn (1997)        0       0   \n1678      1679                           B. Monkey (1998)        0       0   \n1679      1680                       Sliding Doors (1998)        0       0   \n1680      1681                        You So Crazy (1994)        0       0   \n1681      1682  Scream of Stone (Schrei aus Stein) (1991)        0       0   \n\n      Adventure  Animation  Children's  Comedy  Crime  Documentary  ...  \\\n0             0          1           1       1      0            0  ...   \n1             1          0           0       0      0            0  ...   \n2             0          0           0       0      0            0  ...   \n3             0          0           0       1      0            0  ...   \n4             0          0           0       0      1            0  ...   \n...         ...        ...         ...     ...    ...          ...  ...   \n1677          0          0           0       0      0            0  ...   \n1678          0          0           0       0      0            0  ...   \n1679          0          0           0       0      0            0  ...   \n1680          0          0           0       1      0            0  ...   \n1681          0          0           0       0      0            0  ...   \n\n      Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  \\\n0             0       0        0        0        0       0         0    0   \n1             0       0        0        0        0       0         1    0   \n2             0       0        0        0        0       0         1    0   \n3             0       0        0        0        0       0         0    0   \n4             0       0        0        0        0       0         1    0   \n...         ...     ...      ...      ...      ...     ...       ...  ...   \n1677          0       0        0        0        0       0         0    0   \n1678          0       0        0        0        1       0         1    0   \n1679          0       0        0        0        1       0         0    0   \n1680          0       0        0        0        0       0         0    0   \n1681          0       0        0        0        0       0         0    0   \n\n      Western  release_year  \n0           0        1995.0  \n1           0        1995.0  \n2           0        1995.0  \n3           0        1995.0  \n4           0        1995.0  \n...       ...           ...  \n1677        0        1998.0  \n1678        0        1998.0  \n1679        0        1998.0  \n1680        0        1994.0  \n1681        0        1996.0  \n\n[1682 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>movie_title</th>\n      <th>unknown</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children's</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>Documentary</th>\n      <th>...</th>\n      <th>Film-Noir</th>\n      <th>Horror</th>\n      <th>Musical</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n      <th>War</th>\n      <th>Western</th>\n      <th>release_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Four Rooms (1995)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Get Shorty (1995)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Copycat (1995)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1677</th>\n      <td>1678</td>\n      <td>Mat' i syn (1997)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1998.0</td>\n    </tr>\n    <tr>\n      <th>1678</th>\n      <td>1679</td>\n      <td>B. Monkey (1998)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1998.0</td>\n    </tr>\n    <tr>\n      <th>1679</th>\n      <td>1680</td>\n      <td>Sliding Doors (1998)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1998.0</td>\n    </tr>\n    <tr>\n      <th>1680</th>\n      <td>1681</td>\n      <td>You So Crazy (1994)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1994.0</td>\n    </tr>\n    <tr>\n      <th>1681</th>\n      <td>1682</td>\n      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1996.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1682 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:40.263765500Z",
     "start_time": "2023-12-01T14:16:40.219252400Z"
    }
   },
   "id": "341b1c3bc755dea9"
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/53 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93a2112486be4bba9cbe6fa00b2f80ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def SequenceEncoder(movie_titles , model_name=None):\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    title_embeddings = model.encode(movie_titles, show_progress_bar=True,\n",
    "                              convert_to_tensor=True, device=device)\n",
    "    \n",
    "    return title_embeddings.to(\"cpu\")\n",
    "\n",
    "item_title = SequenceEncoder(items[\"movie_title\"], model_name='all-MiniLM-L6-v2')\n",
    "item_genres = torch.tensor(items[genres.name].to_numpy(), dtype=torch.bool)\n",
    "item_release_year = torch.tensor(items[\"release_year\"].to_numpy()[:,np.newaxis], dtype=torch.int32)\n",
    "\n",
    "item_x = torch.cat((item_title, item_genres), dim=-1).float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.282908Z",
     "start_time": "2023-12-01T14:16:40.236257500Z"
    }
   },
   "id": "a201cb82c6e6699e"
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "outputs": [
    {
     "data": {
      "text/plain": "     user_id  age zip_code   male  female  occupation_technician  \\\n0          1   24    85711   True   False                   True   \n1          2   53    94043  False    True                  False   \n2          3   23    32067   True   False                  False   \n3          4   24    43537   True   False                   True   \n4          5   33    15213  False    True                  False   \n..       ...  ...      ...    ...     ...                    ...   \n938      939   26    33319  False    True                  False   \n939      940   32    02215   True   False                  False   \n940      941   20    97229   True   False                  False   \n941      942   48    78209  False    True                  False   \n942      943   22    77841   True   False                  False   \n\n     occupation_other  occupation_writer  occupation_executive  \\\n0               False              False                 False   \n1                True              False                 False   \n2               False               True                 False   \n3               False              False                 False   \n4                True              False                 False   \n..                ...                ...                   ...   \n938             False              False                 False   \n939             False              False                 False   \n940             False              False                 False   \n941             False              False                 False   \n942             False              False                 False   \n\n     occupation_administrator  ...  occupation_librarian  \\\n0                       False  ...                 False   \n1                       False  ...                 False   \n2                       False  ...                 False   \n3                       False  ...                 False   \n4                       False  ...                 False   \n..                        ...  ...                   ...   \n938                     False  ...                 False   \n939                      True  ...                 False   \n940                     False  ...                 False   \n941                     False  ...                  True   \n942                     False  ...                 False   \n\n     occupation_homemaker  occupation_artist  occupation_engineer  \\\n0                   False              False                False   \n1                   False              False                False   \n2                   False              False                False   \n3                   False              False                False   \n4                   False              False                False   \n..                    ...                ...                  ...   \n938                 False              False                False   \n939                 False              False                False   \n940                 False              False                False   \n941                 False              False                False   \n942                 False              False                False   \n\n     occupation_marketing  occupation_none  occupation_healthcare  \\\n0                   False            False                  False   \n1                   False            False                  False   \n2                   False            False                  False   \n3                   False            False                  False   \n4                   False            False                  False   \n..                    ...              ...                    ...   \n938                 False            False                  False   \n939                 False            False                  False   \n940                 False            False                  False   \n941                 False            False                  False   \n942                 False            False                  False   \n\n     occupation_retired  occupation_salesman  occupation_doctor  \n0                 False                False              False  \n1                 False                False              False  \n2                 False                False              False  \n3                 False                False              False  \n4                 False                False              False  \n..                  ...                  ...                ...  \n938               False                False              False  \n939               False                False              False  \n940               False                False              False  \n941               False                False              False  \n942               False                False              False  \n\n[943 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>zip_code</th>\n      <th>male</th>\n      <th>female</th>\n      <th>occupation_technician</th>\n      <th>occupation_other</th>\n      <th>occupation_writer</th>\n      <th>occupation_executive</th>\n      <th>occupation_administrator</th>\n      <th>...</th>\n      <th>occupation_librarian</th>\n      <th>occupation_homemaker</th>\n      <th>occupation_artist</th>\n      <th>occupation_engineer</th>\n      <th>occupation_marketing</th>\n      <th>occupation_none</th>\n      <th>occupation_healthcare</th>\n      <th>occupation_retired</th>\n      <th>occupation_salesman</th>\n      <th>occupation_doctor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>85711</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>53</td>\n      <td>94043</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23</td>\n      <td>32067</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24</td>\n      <td>43537</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>33</td>\n      <td>15213</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>938</th>\n      <td>939</td>\n      <td>26</td>\n      <td>33319</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>940</td>\n      <td>32</td>\n      <td>02215</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>941</td>\n      <td>20</td>\n      <td>97229</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>942</td>\n      <td>48</td>\n      <td>78209</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>943</td>\n      <td>22</td>\n      <td>77841</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.298908Z",
     "start_time": "2023-12-01T14:16:41.280908700Z"
    }
   },
   "id": "d1942a41fd8d13cb"
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['85711', '94043', '32067', '43537', '15213', '98101', '91344',\n       '05201', '01002', '90703', '30329', '06405', '29206', '55106',\n       '97301', '10309', '06355', '37212', '02138', '95660', '30068',\n       '40206', '48197', '94533', '55107', '21044', '30030', '55369',\n       '94043', '55436', '10003', '78741', '27510', '42141', '42459',\n       '93117', '55105', '54467', '01040', '27514', '80525', '17870',\n       '20854', '46260', '50233', '46538', '07102', '12550', '76111',\n       '52245', '16509', '55105', '55414', '66315', '01331', '46260',\n       '84010', '52246', '08403', '06472', '30040', '97214', '75240',\n       '43202', '48118', '80521', '60402', '22904', '55337', '60067',\n       '98034', '73034', '41850', 'T8H1N', '08816', '02215', '29379',\n       '61801', '03755', '52241', '21218', '22902', '44133', '55369',\n       '20003', '46005', '89503', '11701', '68106', '78155', '01913',\n       '80525', '23112', '71457', '10707', '75206', '98006', '90291',\n       '63129', '90254', '05146', '30220', '55108', '55108', '94043',\n       '55125', '60466', '63130', '55423', '77840', '90630', '60613',\n       '95032', '75013', '17110', '97232', '16125', '90210', '67401',\n       '06260', '99603', '22206', '20008', '60615', '22202', '20015',\n       '73439', '20009', '07039', '60115', '15237', '94612', '78602',\n       '80236', '38401', '97365', '84408', '53211', '08904', '32250',\n       '36117', '48118', '08832', '20910', 'V3N4P', '83814', '02143',\n       '97006', '17325', '02139', '48103', '68767', '60641', '53703',\n       '11217', '08360', '70808', '27606', '55346', '66215', '55104',\n       '15610', '97212', '80123', '53715', '55113', 'L9G2B', '80127',\n       '53705', '30067', '78750', '22207', '22306', '52302', '21911',\n       '07030', '19104', '49512', '20755', '60202', '21218', '33884',\n       '27708', '76013', '97403', '00000', '16801', '29440', '95014',\n       '95938', '95161', '90840', '49931', '02154', '93555', '55105',\n       '75094', '55414', '17604', '93402', 'E2A4H', '60201', '32301',\n       '10960', '06371', '53115', '92037', '01720', '85710', '03060',\n       '32605', '61401', '55345', '11231', '63033', '02215', '11727',\n       '06513', '43212', '78205', '20685', '27502', '47906', '43512',\n       '58202', '92103', '60659', '22003', '22903', '14476', '01080',\n       '99709', '98682', '94702', '22973', '53214', '63146', '44124',\n       '95628', '20784', '20001', '31404', '60201', '80525', '55109',\n       '28734', '20770', '37235', '84103', '95110', '85032', '07733',\n       '22903', '42647', '07029', '39042', '77005', '77801', '48823',\n       '89801', '85202', '78264', '55346', '90064', '84601', '78756',\n       '83716', '19422', '43201', '63119', '22932', '53706', '10016',\n       '55414', '92064', '95064', '55406', '30033', '85251', '22903',\n       '06059', '20057', '55305', '92629', '53713', '15217', '31211',\n       '23226', '94619', '93550', '44106', '94703', '60804', '92110',\n       '50325', '16803', '98103', '01581', '63108', '55106', '55439',\n       '77904', '14853', '71701', '94086', '73132', '55454', '95076',\n       '70802', '91711', '73071', '02110', '60035', '08043', '18301',\n       '77009', '13210', '06518', '22030', '24060', '55413', '50613',\n       '19149', '02176', '02139', '15235', '11101', '06779', '01720',\n       '33884', '91344', '40504', 'V0R2M', '30002', '33775', '42101',\n       '10522', '59717', '37901', '80123', '44405', '98006', '30093',\n       '94117', '94143', '76059', '90210', '45660', '61455', '97301',\n       '49938', '55105', '28480', '48197', '60135', '92688', '98133',\n       '10022', '61801', '98027', '44074', '85233', '87501', '01810',\n       '20009', '50670', '37411', '92113', '91335', '08534', '99206',\n       '66046', '55116', '78746', '37777', '10010', '18015', '02859',\n       '98117', '55117', '94608', '01824', '75204', '45218', '10003',\n       '43221', '37412', '36106', '83702', '85016', '84604', '59801',\n       '83686', '96819', '44092', '94551', '27514', '60008', '92374',\n       '78213', '84107', '95129', '06811', '55108', '10019', '93109',\n       '03261', '61755', '98225', '94025', '44691', '15222', '78212',\n       '38115', '85711', '92626', '48103', '21206', '43215', '02140',\n       '55105', '94533', '91606', '55422', '58644', '01602', '85258',\n       '55414', '29205', '98199', '92629', '50311', '11211', '49705',\n       '60007', '17345', '20009', '43204', '20817', '48076', '55013',\n       '85282', '33308', '53202', '92653', '60201', '55113', '10021',\n       '55021', '11758', '48446', '28018', '06333', '97330', '83709',\n       '31820', '30011', 'Y1A6B', '29201', '60630', '98102', '02918',\n       '75218', '94583', '05001', '90804', '91201', '02341', '78628',\n       '10021', '77459', '87544', '94708', '93711', '75230', '60440',\n       '02125', '10019', '55409', '98257', '37771', '40256', '43212',\n       '21208', '95821', '93101', '92121', '21012', '45218', 'V5A2B',\n       '53711', '94618', '60090', '49428', '03052', '55414', '50112',\n       '55408', '75006', '94305', '10025', '23092', '27514', '92115',\n       '20657', '03869', '28450', '19382', '10011', '98038', '21250',\n       '20090', '26241', '20707', '49508', '10021', '55454', '99709',\n       '55320', '12603', '02146', '55443', '04102', '02159', '19711',\n       '97124', '12180', '55104', '44224', '94040', '97408', '92705',\n       '02324', '05464', '80302', '30078', '22902', '21010', '80303',\n       '91201', '84302', '60515', '95123', '29464', '08052', '22911',\n       '14534', '95468', '45680', '95453', '55414', '68147', '62901',\n       '62901', '23227', '30606', '11217', '63132', '10022', '10003',\n       '60005', '20879', '32707', '94591', '55422', '14627', '10003',\n       '01915', '91903', '14627', '01945', '20003', '48911', '53188',\n       '46032', '98281', '77845', 'M7A1A', '48103', '17961', '94131',\n       '93003', '29631', '27511', '98501', '79508', '14216', '93063',\n       '90034', '82435', '92093', '97520', '68767', 'M4J2K', '31909',\n       '77073', '84116', '43085', 'R3T5K', '02320', '99687', '34656',\n       '47905', '11787', '33716', '63044', '02154', '10003', '55106',\n       '21227', '77008', '79070', '29678', '80227', '27705', '50613',\n       '11201', '44212', '44134', '81648', '60402', '14850', '60187',\n       '30067', '20723', '19807', '08034', '94306', '44224', '55408',\n       '38866', '55454', '55414', 'T8H1N', '23237', '48043', '74101',\n       '01940', '12065', '61801', '60626', '95521', '55122', '63645',\n       '53211', '51250', '45810', '91351', '39762', '83814', '02903',\n       '22911', '55105', '78739', '60657', '10314', '78704', '92626',\n       '54248', '77380', '98121', '19102', '19341', '94115', '55412',\n       '61820', '01970', '10016', '20009', '21114', '91919', '90095',\n       '22906', '55337', '28814', '32712', '99835', '61462', '54302',\n       '90405', '97208', '55128', '23509', '55414', '55409', '26506',\n       '27713', '60476', '45439', '63304', '60089', '18053', '85210',\n       '06365', '38115', '94920', '77042', '06906', '96754', '76309',\n       '56321', '89104', '49512', '91105', '54494', '55454', '19146',\n       '96349', 'N4T1A', '92020', '15203', '54901', '07204', '55343',\n       '91206', '44265', '84105', '64118', 'V0R2H', '16506', '11238',\n       '17331', '94403', '40243', '91711', '80538', '78741', '94306',\n       '56567', '32114', '70403', '98405', '60630', '63108', '85719',\n       '94618', '98072', '95403', '73162', '22206', '63108', '29210',\n       '92660', '47024', '55113', '19047', '93612', '94720', '80919',\n       '32303', '90034', '21201', '91206', '62901', '97007', '90247',\n       '55104', '53706', '68503', '14211', '97302', '95050', '02113',\n       '62903', '33066', '10960', '00000', '12866', '06927', '14216',\n       '15232', '27105', '55414', '80027', '90036', '51157', '01810',\n       '01960', 'K7L5J', '94560', '48825', '33205', '77081', '91040',\n       '23322', '01754', '98620', '05779', '55420', '80913', '20064',\n       '12205', '85281', '57197', '08610', '33755', '62522', '64131',\n       '19716', '55337', '92154', '34105', '78212', '61820', '20009',\n       '11217', '93555', '90016', '30803', '80526', '73013', '76234',\n       '02136', '12345', '28806', '20755', '60152', '27514', '40205',\n       '37725', '77845', '53144', '50322', '15017', '05452', '77048',\n       '80228', '85282', '80209', '53066', '33765', '77042', '90019',\n       '64153', '11577', '10018', '55409', '01375', '90814', '55406',\n       '47401', '93055', '44212', '95662', '97405', '47130', '55417',\n       '02146', '25652', '78390', '29646', '94086', '40515', '55408',\n       '04988', '97215', 'V1G4L', '09645', '06492', '48322', '14085',\n       '13820', '60089', '63021', '11231', '60302', '92507', '55303',\n       '10025', '65203', '44648', '74078', '33763', '37076', '35802',\n       '20902', '77504', '98027', '55337', '83702', '43017', '40503',\n       '50266', '55337', '95316', '61820', '27249', '17036', '78704',\n       '97301', '03062', '45243', '95823', '74075', '32301', '91505',\n       '33484', '61755', '55116', '18505', 'L1V3W', '97203', '20850',\n       '61073', '30350', '70124', '80526', '68504', '53171', '29301',\n       '53210', '06512', '76201', '08105', '60614', 'N2L5N', '20006',\n       '70116', '14216', '90008', '98801', '21114', 'E2E3R', '11753',\n       '49036', '01701', '55428', '55408', '53711', '07310', '33556',\n       '06437', '48105', '22902', '66221', '32789', '98072', '55038',\n       '33319', '02215', '97229', '78209', '77841'], dtype=object)"
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.zip_code.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.325908300Z",
     "start_time": "2023-12-01T14:16:41.295907800Z"
    }
   },
   "id": "d496e7bffcfd2278"
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "outputs": [],
   "source": [
    "user_ages = torch.tensor(users[\"age\"].to_numpy()[:,np.newaxis], dtype=torch.uint8)\n",
    "user_sex = torch.tensor(users[[\"male\", \"female\"]].to_numpy(), dtype=torch.bool)\n",
    "occupations = [i for i in users.keys() if i.startswith(\"occupation_\")]\n",
    "user_occupation = torch.tensor(users[occupations].to_numpy(), dtype=torch.bool)\n",
    "user_x = torch.cat((user_ages, user_sex, user_occupation), dim=-1).float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.358430900Z",
     "start_time": "2023-12-01T14:16:41.311908Z"
    }
   },
   "id": "38af715c6383f78e"
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# data['user'].num_nodes = len(users)\n",
    "# data['user'].x = torch.eye(data['user'].num_nodes, device=device)\n",
    "# del data['user'].num_nodes\n",
    "data['user'].x = user_x\n",
    "data['item'].x = item_x\n",
    "data['user', 'rates', 'item'].edge_index = edge_index\n",
    "data['user', 'rates', 'item'].edge_label = edge_attr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.400431700Z",
     "start_time": "2023-12-01T14:16:41.327912200Z"
    }
   },
   "id": "48d66c8cb0521265"
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "outputs": [],
   "source": [
    "data = ToUndirected()(data)\n",
    "del data['item', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n",
    "data = data.to(device)\n",
    "\n",
    "# Perform a link-level split into training, validation, and test edges.\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'item')],\n",
    "    rev_edge_types=[('item', 'rev_rates', 'user')],\n",
    ")(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.409432100Z",
     "start_time": "2023-12-01T14:16:41.348431100Z"
    }
   },
   "id": "1b42a5cb4e8e1e35"
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "outputs": [],
   "source": [
    "weight = torch.bincount(train_data['user', 'rates', 'item'].edge_label)\n",
    "weight = weight.max() / weight\n",
    "def weighted_mse_loss(pred, target, weight=None):\n",
    "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
    "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.410431600Z",
     "start_time": "2023-12-01T14:16:41.376430900Z"
    }
   },
   "id": "c288c9c483405a7e"
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "outputs": [],
   "source": [
    "from torch.nn import Dropout\n",
    "from torch_geometric.nn import GATv2Conv, RGCNConv, HeteroConv, GINConv\n",
    "from torch_geometric.utils.dropout import *\n",
    "\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # these convolutions have been replicated to match the number of edge types\\\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, n_factors, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * n_factors, hidden_channels)\n",
    "        self.dropout1 = Dropout(p=0.5)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.dropout2 = Dropout(p=0.5)\n",
    "        self.lin3 = Linear(hidden_channels, hidden_channels)\n",
    "        self.dropout3 = Dropout(p=0.25)\n",
    "        self.lin4 = Linear(hidden_channels, 1)\n",
    "        \n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        # concat user and movie embeddings\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['item'][col]], dim=-1)\n",
    "        # concatenated embeddings passed to linear layer\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.dropout1(z)\n",
    "        z = self.lin2(z).relu()\n",
    "        z = self.dropout2(z)\n",
    "        z = self.lin3(z).relu()\n",
    "        z = self.dropout3(z)\n",
    "        z = self.lin4(z)\n",
    "        return z.view(-1)\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, n_factors, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(n_factors)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(n_factors, hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        # z_dict contains dictionary of movie and user embeddings returned from GraphSage\n",
    "        edge_label_index, mask = dropout_edge(edge_label_index, p=0.02, training=self.training)\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        output = self.decoder(z_dict, edge_label_index)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output * 4 + 1\n",
    "        return output, mask\n",
    "model = Model(n_factors=150, hidden_channels=200).to(device)\n",
    "# Due to lazy initialization, we need to run one model step so the number\n",
    "# of parameters can be inferred:\n",
    "with torch.no_grad():\n",
    "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.428435600Z",
     "start_time": "2023-12-01T14:16:41.397430800Z"
    }
   },
   "id": "1ad44484c84b9b28"
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (encoder): GraphModule(\n",
      "    (conv1): ModuleDict(\n",
      "      (user__rates__item): SAGEConv((-1, -1), 150, aggr=mean)\n",
      "      (item__rev_rates__user): SAGEConv((-1, -1), 150, aggr=mean)\n",
      "    )\n",
      "    (conv2): ModuleDict(\n",
      "      (user__rates__item): SAGEConv((-1, -1), 150, aggr=mean)\n",
      "      (item__rev_rates__user): SAGEConv((-1, -1), 150, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (decoder): EdgeDecoder(\n",
      "    (lin1): Linear(in_features=300, out_features=200, bias=True)\n",
      "    (dropout1): Dropout(p=0.5, inplace=False)\n",
      "    (lin2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (dropout2): Dropout(p=0.5, inplace=False)\n",
      "    (lin3): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (dropout3): Dropout(p=0.25, inplace=False)\n",
      "    (lin4): Linear(in_features=200, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.467946100Z",
     "start_time": "2023-12-01T14:16:41.423430100Z"
    }
   },
   "id": "cdec0941bb113c0"
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "loss_f = MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred, mask = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['user', 'rates', 'item'].edge_label_index)\n",
    "    target = train_data['user', 'rates', 'item'].edge_label\n",
    "    loss = weighted_mse_loss(pred, target[mask], weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.475947700Z",
     "start_time": "2023-12-01T14:16:41.440437300Z"
    }
   },
   "id": "6d258c1985d72b5b"
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    pred, _ = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['user', 'rates', 'item'].edge_label_index)\n",
    "    target = data['user', 'rates', 'item'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:41.476947200Z",
     "start_time": "2023-12-01T14:16:41.454946400Z"
    }
   },
   "id": "d55867059c4f30f"
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 3.3564, Train: 1.2022, Val: 1.2068, Test: 1.2006\n",
      "Epoch: 002, Loss: 3.3476, Train: 1.2554, Val: 1.2599, Test: 1.2529\n",
      "Epoch: 003, Loss: 3.3454, Train: 1.2023, Val: 1.2067, Test: 1.2007\n",
      "Epoch: 004, Loss: 3.3234, Train: 1.2388, Val: 1.2429, Test: 1.2364\n",
      "Epoch: 005, Loss: 3.3044, Train: 1.1974, Val: 1.2015, Test: 1.1958\n",
      "Epoch: 006, Loss: 3.2884, Train: 1.2843, Val: 1.2887, Test: 1.2817\n",
      "Epoch: 007, Loss: 3.3063, Train: 1.1239, Val: 1.1287, Test: 1.1247\n",
      "Epoch: 008, Loss: 3.4592, Train: 1.1989, Val: 1.2038, Test: 1.1985\n",
      "Epoch: 009, Loss: 3.2758, Train: 1.3758, Val: 1.3815, Test: 1.3748\n",
      "Epoch: 010, Loss: 3.4464, Train: 1.2596, Val: 1.2654, Test: 1.2597\n",
      "Epoch: 011, Loss: 3.3096, Train: 1.2118, Val: 1.2174, Test: 1.2125\n",
      "Epoch: 012, Loss: 3.3261, Train: 1.2003, Val: 1.2058, Test: 1.2009\n",
      "Epoch: 013, Loss: 3.3287, Train: 1.2066, Val: 1.2121, Test: 1.2070\n",
      "Epoch: 014, Loss: 3.3177, Train: 1.2205, Val: 1.2255, Test: 1.2204\n",
      "Epoch: 015, Loss: 3.3214, Train: 1.2116, Val: 1.2162, Test: 1.2111\n",
      "Epoch: 016, Loss: 3.3151, Train: 1.1930, Val: 1.1974, Test: 1.1925\n",
      "Epoch: 017, Loss: 3.2919, Train: 1.2170, Val: 1.2214, Test: 1.2161\n",
      "Epoch: 018, Loss: 3.2749, Train: 1.2233, Val: 1.2279, Test: 1.2226\n",
      "Epoch: 019, Loss: 3.2698, Train: 1.2021, Val: 1.2066, Test: 1.2018\n",
      "Epoch: 020, Loss: 3.2728, Train: 1.2085, Val: 1.2130, Test: 1.2083\n",
      "Epoch: 021, Loss: 3.2523, Train: 1.2224, Val: 1.2269, Test: 1.2221\n",
      "Epoch: 022, Loss: 3.2399, Train: 1.1928, Val: 1.1980, Test: 1.1936\n",
      "Epoch: 023, Loss: 3.2280, Train: 1.2097, Val: 1.2147, Test: 1.2102\n",
      "Epoch: 024, Loss: 3.2087, Train: 1.1993, Val: 1.2045, Test: 1.2002\n",
      "Epoch: 025, Loss: 3.1854, Train: 1.1969, Val: 1.2023, Test: 1.1982\n",
      "Epoch: 026, Loss: 3.1897, Train: 1.1882, Val: 1.1936, Test: 1.1898\n",
      "Epoch: 027, Loss: 3.1787, Train: 1.2198, Val: 1.2253, Test: 1.2209\n",
      "Epoch: 028, Loss: 3.1774, Train: 1.1300, Val: 1.1358, Test: 1.1331\n",
      "Epoch: 029, Loss: 3.2538, Train: 1.3759, Val: 1.3822, Test: 1.3746\n",
      "Epoch: 030, Loss: 3.3784, Train: 1.1702, Val: 1.1758, Test: 1.1728\n",
      "Epoch: 031, Loss: 3.2418, Train: 1.1507, Val: 1.1565, Test: 1.1535\n",
      "Epoch: 032, Loss: 3.3030, Train: 1.1772, Val: 1.1826, Test: 1.1791\n",
      "Epoch: 033, Loss: 3.2502, Train: 1.2398, Val: 1.2452, Test: 1.2403\n",
      "Epoch: 034, Loss: 3.2529, Train: 1.2242, Val: 1.2297, Test: 1.2250\n",
      "Epoch: 035, Loss: 3.2330, Train: 1.1787, Val: 1.1842, Test: 1.1804\n",
      "Epoch: 036, Loss: 3.1878, Train: 1.1826, Val: 1.1882, Test: 1.1842\n",
      "Epoch: 037, Loss: 3.1974, Train: 1.2101, Val: 1.2153, Test: 1.2113\n",
      "Epoch: 038, Loss: 3.1911, Train: 1.1459, Val: 1.1515, Test: 1.1485\n",
      "Epoch: 039, Loss: 3.1855, Train: 1.2215, Val: 1.2264, Test: 1.2224\n",
      "Epoch: 040, Loss: 3.1529, Train: 1.1792, Val: 1.1847, Test: 1.1814\n",
      "Epoch: 041, Loss: 3.1465, Train: 1.1990, Val: 1.2043, Test: 1.2007\n",
      "Epoch: 042, Loss: 3.1390, Train: 1.2185, Val: 1.2239, Test: 1.2198\n",
      "Epoch: 043, Loss: 3.1396, Train: 1.1774, Val: 1.1831, Test: 1.1796\n",
      "Epoch: 044, Loss: 3.1414, Train: 1.1931, Val: 1.1987, Test: 1.1949\n",
      "Epoch: 045, Loss: 3.1206, Train: 1.1971, Val: 1.2028, Test: 1.1990\n",
      "Epoch: 046, Loss: 3.1060, Train: 1.1601, Val: 1.1663, Test: 1.1629\n",
      "Epoch: 047, Loss: 3.1133, Train: 1.2288, Val: 1.2344, Test: 1.2299\n",
      "Epoch: 048, Loss: 3.1116, Train: 1.1416, Val: 1.1480, Test: 1.1447\n",
      "Epoch: 049, Loss: 3.1343, Train: 1.2268, Val: 1.2328, Test: 1.2277\n",
      "Epoch: 050, Loss: 3.1022, Train: 1.1972, Val: 1.2032, Test: 1.1991\n",
      "Epoch: 051, Loss: 3.0685, Train: 1.1538, Val: 1.1603, Test: 1.1567\n",
      "Epoch: 052, Loss: 3.0765, Train: 1.2499, Val: 1.2553, Test: 1.2501\n",
      "Epoch: 053, Loss: 3.1177, Train: 1.1027, Val: 1.1091, Test: 1.1063\n",
      "Epoch: 054, Loss: 3.2409, Train: 1.2113, Val: 1.2168, Test: 1.2118\n",
      "Epoch: 055, Loss: 3.0845, Train: 1.2728, Val: 1.2790, Test: 1.2725\n",
      "Epoch: 056, Loss: 3.1561, Train: 1.1644, Val: 1.1709, Test: 1.1672\n",
      "Epoch: 057, Loss: 3.1105, Train: 1.1516, Val: 1.1580, Test: 1.1547\n",
      "Epoch: 058, Loss: 3.0999, Train: 1.2468, Val: 1.2519, Test: 1.2467\n",
      "Epoch: 059, Loss: 3.1436, Train: 1.1270, Val: 1.1338, Test: 1.1305\n",
      "Epoch: 060, Loss: 3.1167, Train: 1.1712, Val: 1.1768, Test: 1.1734\n",
      "Epoch: 061, Loss: 3.0515, Train: 1.2617, Val: 1.2669, Test: 1.2609\n",
      "Epoch: 062, Loss: 3.1177, Train: 1.1290, Val: 1.1354, Test: 1.1320\n",
      "Epoch: 063, Loss: 3.1079, Train: 1.1568, Val: 1.1626, Test: 1.1588\n",
      "Epoch: 064, Loss: 3.0671, Train: 1.2575, Val: 1.2628, Test: 1.2563\n",
      "Epoch: 065, Loss: 3.1211, Train: 1.1473, Val: 1.1535, Test: 1.1499\n",
      "Epoch: 066, Loss: 3.0484, Train: 1.1454, Val: 1.1520, Test: 1.1481\n",
      "Epoch: 067, Loss: 3.0468, Train: 1.2474, Val: 1.2522, Test: 1.2467\n",
      "Epoch: 068, Loss: 3.0797, Train: 1.1653, Val: 1.1711, Test: 1.1673\n",
      "Epoch: 069, Loss: 3.0295, Train: 1.1384, Val: 1.1451, Test: 1.1412\n",
      "Epoch: 070, Loss: 3.0419, Train: 1.1918, Val: 1.1975, Test: 1.1930\n",
      "Epoch: 071, Loss: 3.0038, Train: 1.2265, Val: 1.2320, Test: 1.2269\n",
      "Epoch: 072, Loss: 3.0261, Train: 1.1649, Val: 1.1714, Test: 1.1673\n",
      "Epoch: 073, Loss: 3.0108, Train: 1.1534, Val: 1.1601, Test: 1.1561\n",
      "Epoch: 074, Loss: 3.0125, Train: 1.2055, Val: 1.2114, Test: 1.2064\n",
      "Epoch: 075, Loss: 2.9985, Train: 1.1752, Val: 1.1815, Test: 1.1772\n",
      "Epoch: 076, Loss: 2.9913, Train: 1.1558, Val: 1.1628, Test: 1.1586\n",
      "Epoch: 077, Loss: 2.9904, Train: 1.1908, Val: 1.1973, Test: 1.1927\n",
      "Epoch: 078, Loss: 2.9827, Train: 1.1952, Val: 1.2018, Test: 1.1969\n",
      "Epoch: 079, Loss: 2.9823, Train: 1.1571, Val: 1.1644, Test: 1.1601\n",
      "Epoch: 080, Loss: 2.9779, Train: 1.1670, Val: 1.1742, Test: 1.1698\n",
      "Epoch: 081, Loss: 2.9728, Train: 1.2042, Val: 1.2110, Test: 1.2057\n",
      "Epoch: 082, Loss: 2.9753, Train: 1.1782, Val: 1.1852, Test: 1.1806\n",
      "Epoch: 083, Loss: 2.9620, Train: 1.1546, Val: 1.1620, Test: 1.1578\n",
      "Epoch: 084, Loss: 2.9688, Train: 1.1897, Val: 1.1964, Test: 1.1914\n",
      "Epoch: 085, Loss: 2.9637, Train: 1.1855, Val: 1.1923, Test: 1.1874\n",
      "Epoch: 086, Loss: 2.9588, Train: 1.1550, Val: 1.1625, Test: 1.1581\n",
      "Epoch: 087, Loss: 2.9547, Train: 1.1782, Val: 1.1852, Test: 1.1805\n",
      "Epoch: 088, Loss: 2.9415, Train: 1.1902, Val: 1.1974, Test: 1.1924\n",
      "Epoch: 089, Loss: 2.9428, Train: 1.1631, Val: 1.1708, Test: 1.1663\n",
      "Epoch: 090, Loss: 2.9371, Train: 1.1749, Val: 1.1824, Test: 1.1776\n",
      "Epoch: 091, Loss: 2.9374, Train: 1.1877, Val: 1.1950, Test: 1.1900\n",
      "Epoch: 092, Loss: 2.9296, Train: 1.1633, Val: 1.1710, Test: 1.1664\n",
      "Epoch: 093, Loss: 2.9387, Train: 1.1744, Val: 1.1820, Test: 1.1771\n",
      "Epoch: 094, Loss: 2.9239, Train: 1.1899, Val: 1.1975, Test: 1.1923\n",
      "Epoch: 095, Loss: 2.9282, Train: 1.1623, Val: 1.1707, Test: 1.1662\n",
      "Epoch: 096, Loss: 2.9195, Train: 1.1814, Val: 1.1899, Test: 1.1850\n",
      "Epoch: 097, Loss: 2.9216, Train: 1.1954, Val: 1.2041, Test: 1.1987\n",
      "Epoch: 098, Loss: 2.9185, Train: 1.1589, Val: 1.1679, Test: 1.1632\n",
      "Epoch: 099, Loss: 2.9068, Train: 1.1843, Val: 1.1930, Test: 1.1875\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:18:40.114202100Z",
     "start_time": "2023-12-01T14:17:14.853832400Z"
    }
   },
   "id": "b3bb283aa6640b24"
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "print(len(items))\n",
    "print(items[\"movie_id\"].max())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:18:47.219474200Z",
     "start_time": "2023-12-01T14:18:47.195472200Z"
    }
   },
   "id": "5a442545fb43467c"
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-min diff:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:00,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tensor(2.9038, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Max-min diff: tensor(2.8942, device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-min diff: tensor(2.9220, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Max-min diff: tensor(2.8833, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Max-min diff: tensor(2.8587, device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "total_users = len(users)\n",
    "total_movies = len(items)\n",
    "movie_recs = []\n",
    "for user_id in tqdm(range(0, 5)):\n",
    "    all_movie_ids = torch.arange(total_movies)\n",
    "    seen_movie_ids = ratings[ratings[\"user_id\"] == user_id + 1][\"item_id\"].unique()\n",
    "    seen_movie_ids = np.array(seen_movie_ids)\n",
    "    check_movies = []\n",
    "    for i in all_movie_ids:\n",
    "        if not np.any(seen_movie_ids == i):\n",
    "            check_movies.append(i)\n",
    "    check_movies = torch.tensor(check_movies)\n",
    "    user_row = torch.tensor([user_id] * check_movies.shape[0])\n",
    "    edge_label_index = torch.stack([user_row, check_movies], dim=0)\n",
    "    pred, _ = model(data.x_dict, data.edge_index_dict,\n",
    "             edge_label_index)\n",
    "    print(\"Max-min diff:\", torch.max(pred) - torch.min(pred))\n",
    "    # we will only select movies for the user where the predicting rating is =5\n",
    "    rec_movie_ids = torch.argsort(pred, descending=True)[:10]\n",
    "    top_ten_recs = [(rec_movies + 1, pred[rec_movies].item()) for rec_movies in rec_movie_ids.tolist()] \n",
    "    movie_recs.append({'user': user_id + 1, 'rec_movies': top_ten_recs})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:18:47.835567100Z",
     "start_time": "2023-12-01T14:18:47.217473300Z"
    }
   },
   "id": "62c84c7bc07998ba"
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'user': 1,\n  'rec_movies': [(1453, 4.2366132736206055),\n   (1455, 4.215634822845459),\n   (1201, 4.142112731933594),\n   (1447, 4.1298723220825195),\n   (1452, 4.123170852661133),\n   (1461, 4.070978164672852),\n   (1515, 4.070932388305664),\n   (822, 4.04030704498291),\n   (1460, 4.039809226989746),\n   (1458, 4.036356449127197)]},\n {'user': 2,\n  'rec_movies': [(1453, 4.247032165527344),\n   (1455, 4.228955268859863),\n   (1201, 4.156125068664551),\n   (1447, 4.144463539123535),\n   (1452, 4.137075424194336),\n   (1515, 4.085538387298584),\n   (1461, 4.085407257080078),\n   (1460, 4.055061340332031),\n   (822, 4.052642822265625),\n   (1458, 4.050773620605469)]},\n {'user': 3,\n  'rec_movies': [(1453, 4.190402030944824),\n   (1455, 4.171685218811035),\n   (1201, 4.095126152038574),\n   (1447, 4.082378387451172),\n   (1452, 4.075459003448486),\n   (1461, 4.02131462097168),\n   (1515, 4.021267890930176),\n   (822, 3.9893100261688232),\n   (1460, 3.989076852798462),\n   (1458, 3.9855778217315674)]},\n {'user': 4,\n  'rec_movies': [(1453, 4.250977993011475),\n   (1455, 4.230037689208984),\n   (1201, 4.154431343078613),\n   (1447, 4.142313003540039),\n   (1452, 4.135698318481445),\n   (1461, 4.084053993225098),\n   (1515, 4.084031105041504),\n   (822, 4.053998947143555),\n   (1460, 4.053227424621582),\n   (1458, 4.0498151779174805)]},\n {'user': 5,\n  'rec_movies': [(1453, 4.277050018310547),\n   (1455, 4.256874084472656),\n   (1201, 4.182021141052246),\n   (1447, 4.170220375061035),\n   (1452, 4.163762092590332),\n   (1515, 4.113310813903809),\n   (1461, 4.113304138183594),\n   (1460, 4.083193778991699),\n   (822, 4.082226276397705),\n   (1458, 4.079669952392578)]}]"
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_recs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:18:47.876571200Z",
     "start_time": "2023-12-01T14:18:47.834566800Z"
    }
   },
   "id": "6b15a707d27ccd21"
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "outputs": [],
   "source": [
    "user = 4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:18:47.879572100Z",
     "start_time": "2023-12-01T14:18:47.849565Z"
    }
   },
   "id": "3e4928b6f6dea04a"
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mimic (1997) 3 2.7\n",
      "Ulee's Gold (1997) 5 3.6\n",
      "Incognito (1997) 5 3.5\n",
      "One Flew Over the Cuckoo's Nest (1975) 4 4.2\n",
      "Event Horizon (1997) 4 2.5\n",
      "Client, The (1994) 3 3.3\n",
      "Liar Liar (1997) 5 3.1\n",
      "Scream (1996) 4 3.4\n",
      "Star Wars (1977) 5 4.3\n",
      "Wedding Singer, The (1998) 5 3.4\n",
      "Starship Troopers (1997) 4 3.2\n",
      "Air Force One (1997) 5 3.6\n",
      "Conspiracy Theory (1997) 3 3.4\n",
      "Contact (1997) 5 3.8\n",
      "Indiana Jones and the Last Crusade (1989) 3 3.9\n",
      "Desperate Measures (1998) 5 3.3\n",
      "Seven (Se7en) (1995) 4 3.8\n",
      "Cop Land (1997) 5 3.3\n",
      "Lost Highway (1997) 5 3.1\n",
      "Assignment, The (1997) 5 3.5\n",
      "Blues Brothers 2000 (1998) 5 2.8\n",
      "Spawn (1997) 2 2.6\n",
      "Wonderland (1997) 5 3.2\n",
      "In & Out (1997) 5 3.3\n"
     ]
    }
   ],
   "source": [
    "movie_ids = ratings[ratings.user_id == user].iterrows()\n",
    "for i in movie_ids:\n",
    "    _, row = i\n",
    "    item = items[items[\"movie_id\"] == row.item_id]\n",
    "    mean_rating = ratings[ratings[\"item_id\"] == row.item_id][\"rating\"].mean()\n",
    "    print(item[\"movie_title\"].tolist()[0], row.rating, str(mean_rating)[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:18:47.894082200Z",
     "start_time": "2023-12-01T14:18:47.863564900Z"
    }
   },
   "id": "a4e7d12df9000267"
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angel on My Shoulder (1946) 4.2 2.0 1\n",
      "Outlaw, The (1943) 4.2 2.5 2\n",
      "Marlene Dietrich: Shadow and Light (1996)  4.1 5.0 1\n",
      "Century (1993) 4.1 3.0 1\n",
      "Lady of Burlesque (1943) 4.1 4.0 1\n",
      "Here Comes Cookie (1935) 4.0 2.0 1\n",
      "Wings of Courage (1995) 4.0 4.0 1\n",
      "Faces (1968) 4.0 3.0 4\n",
      "Sleepover (1995) 4.0 3.0 1\n",
      "Damsel in Distress, A (1937) 4.0 4.0 1\n"
     ]
    }
   ],
   "source": [
    "for i, r in movie_recs[user - 1][\"rec_movies\"]:\n",
    "    movie = items[items[\"movie_id\"] == i]\n",
    "    movie_id = movie[\"movie_id\"].tolist()[0]\n",
    "    mean_rating = ratings[ratings[\"item_id\"] == movie_id][\"rating\"].mean()\n",
    "    rated = ratings[ratings[\"item_id\"] == movie_id][\"user_id\"].notnull().sum()\n",
    "    print(movie[\"movie_title\"].tolist()[0], str(r)[:3], str(mean_rating)[:3], rated)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:18:47.939081600Z",
     "start_time": "2023-12-01T14:18:47.896084300Z"
    }
   },
   "id": "77f8c036011263f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
